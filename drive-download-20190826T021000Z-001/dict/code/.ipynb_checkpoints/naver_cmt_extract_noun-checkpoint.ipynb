{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import soynlp\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 읽기\n",
    "\n",
    "file_path = 'naver_comments.csv'\n",
    "corpus_path = 'naver_cmt_dic.csv'\n",
    "\n",
    "colnames = ['a', 'b', 'c', 'd']\n",
    "df = pd.read_csv(file_path, encoding='utf-8', header=None, names=colnames)\n",
    "# df = pd.read_excel(file_path, encoding='utf-8', names=colnames)\n",
    "df['b'] = df['b'].dropna().apply(lambda x:''.join([i for i in x \n",
    "                                                  if i not in string.punctuation]))\n",
    "df.iloc[:, 1:2].to_csv(corpus_path, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334633"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>연대 법대출신 토익925점 kt취업vs건대 충주캠 무스펙 귀걸이낀 증명사진 이력서 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>전직 공안 검사 출신 이자나없는 일도 만들고 없던 말도 만들고그렇게 일반인 빵갱이 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>교활이  이새키는  503호뇬 밑에 있을때는 다들 벙어리인줄 알았어헐 근데 지금보니...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지 한심하지 짝이 없는 개누리당</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>연세대나온 아들이 KT간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   b\n",
       "0  연대 법대출신 토익925점 kt취업vs건대 충주캠 무스펙 귀걸이낀 증명사진 이력서 ...\n",
       "1  전직 공안 검사 출신 이자나없는 일도 만들고 없던 말도 만들고그렇게 일반인 빵갱이 ...\n",
       "2  교활이  이새키는  503호뇬 밑에 있을때는 다들 벙어리인줄 알았어헐 근데 지금보니...\n",
       "3       이렇게 입이 가벼운 작자가 어찌 대권을 노린다는건지 한심하지 짝이 없는 개누리당\n",
       "4    연세대나온 아들이 KT간게 뭐대수라고 지잡나온 귀걸이 아빠나 조사해봐라 정권의 개들아"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(corpus_path, encoding='utf-8').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.utils import DoublespaceLineCorpus\n",
    "from soynlp.noun import LRNounExtractor_v2\n",
    "\n",
    "sents = DoublespaceLineCorpus(corpus_path, iter_sent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Noun Extractor] use default predictors\n",
      "[Noun Extractor] num features: pos=1260, neg=1173, common=12\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 939421 from 547626 sents. mem=1.262 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4403996, mem=2.680 Gb\n",
      "[Noun Extractor] counting eojeols\n",
      "[EojeolCounter] n eojeol = 939421 from 547626 sents. mem=2.740 Gb                    \n",
      "[Noun Extractor] complete eojeol counter -> lr graph\n",
      "[Noun Extractor] has been trained. #eojeols=4403996, mem=3.543 Gb\n",
      "[Noun Extractor] batch prediction was completed for 342463 words\n",
      "[Noun Extractor] checked compounds. discovered 257349 compounds\n",
      "[Noun Extractor] postprocessing detaching_features : 1289 -> 1273\n",
      "[Noun Extractor] postprocessing ignore_features : 1273 -> 1214\n",
      "[Noun Extractor] postprocessing ignore_NJ : 1214 -> 1152\n",
      "[Noun Extractor] 1152 nouns (257349 compounds) with min frequency=335\n",
      "[Noun Extractor] flushing was done. mem=3.651 Gb                    \n",
      "[Noun Extractor] 45.41 % eojeols are covered\n"
     ]
    }
   ],
   "source": [
    "noun_extractor = LRNounExtractor_v2(verbose=True, extract_compound=True)\n",
    "noun_extractor.train(sents)\n",
    "nouns = noun_extractor.train_extract(sents, min_noun_frequency=335,\n",
    "                                     min_noun_score=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1045"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [noun for noun, score in nouns.items() if len(noun) > 1]\n",
    "a = [i.replace('\"', '') for i in a] \n",
    "a = [i.replace(\"'\", '') for i in a] \n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "991"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.DataFrame(a, columns=['word'])\n",
    "a['pos'] = 'NNP'\n",
    "a = a[a['word'].str[-1] != '들']\n",
    "# a = a[a['word'].str[-1] != '님']\n",
    "a = a.drop_duplicates()\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.to_csv(corpus_path, encoding='utf-8', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
